"""
test_extended_mmap.py - éªŒè¯æ‰©å±• mmap æ¶æ„ï¼ˆå¤š slot + æ—  .npy fallbackï¼‰

æµ‹è¯•çŸ©é˜µï¼š
  1. å°æ•°ç»„ï¼ˆ< 10 KBï¼‰â€”â€” HTTP inline base64
  2. ä¸­ç­‰æ•°ç»„ï¼ˆ10 KB - 256 MBï¼‰â€”â€” mmap slot ä¼ è¾“
  3. å¤§æ•°ç»„ï¼ˆ256 MB - 1 GBï¼‰â€”â€” å¤š slot è½®è½¬ä¼ è¾“ï¼ˆæ‰©å±• mmapï¼‰
  4. æ€§èƒ½å¯¹æ¯”ï¼šåŸ .npy fallback vs æ–°æ‰©å±• mmap
"""
import sys
import time
import numpy as np

sys.path.insert(0, r"C:\Users\nicho\gpu-sklearn-bridge")
from cuml_proxy.preprocessing import StandardScaler
from cuml_proxy.decomposition import PCA
from cuml_proxy.linear_model import LinearRegression

print("=" * 70)
print(" æ‰©å±• mmap å…±äº«å†…å­˜ä¼ è¾“æµ‹è¯•")
print("=" * 70)

# â”€â”€ 1. å°æ•°ç»„ï¼ˆèµ° base64 inlineï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[1] å°æ•°ç»„ï¼ˆ2Ã—4, ~96 Bï¼‰â€”â€” æœŸæœ›èµ° inline base64")
X_small = np.array([[1.0, 2.0, 3.0, 4.0],
                    [5.0, 6.0, 7.0, 8.0]], dtype=np.float32)
sc = StandardScaler()
out = sc.fit_transform(X_small)
print(f"    è¾“å…¥å½¢çŠ¶: {X_small.shape}  è¾“å‡ºå½¢çŠ¶: {out.shape}")
print(f"    ç»“æœï¼ˆå·²æ ‡å‡†åŒ–ï¼‰:\n{out}")
del sc

# â”€â”€ 2. ä¸­ç­‰æ•°ç»„ï¼ˆ>= 10 KBï¼Œèµ° mmapï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[2] ä¸­ç­‰æ•°ç»„ï¼ˆ1000Ã—20, 80 KBï¼‰â€”â€” æœŸæœ›èµ° mmap")
X_mid = np.random.rand(1000, 20).astype(np.float32)
t0 = time.perf_counter()
sc2 = StandardScaler()
out2 = sc2.fit_transform(X_mid)
elapsed = time.perf_counter() - t0
print(f"    è¾“å…¥å½¢çŠ¶: {X_mid.shape}  è¾“å‡ºå½¢çŠ¶: {out2.shape}")
print(f"    å‡å€¼â‰ˆ0: {out2.mean(axis=0)[:4].round(4)}")
print(f"    æ ‡å‡†å·®â‰ˆ1: {out2.std(axis=0)[:4].round(4)}")
print(f"    è€—æ—¶: {elapsed*1000:.1f} ms")
del sc2

# â”€â”€ 3. å¤§æ•°ç»„ï¼ˆ~100 MBï¼‰â€”â€” å• slot mmap ä¼ è¾“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[3] å¤§æ•°ç»„ï¼ˆ10000Ã—1280, ~100 MBï¼‰â€”â€” å• slot mmap ä¼ è¾“")
X_big_100mb = np.random.rand(10000, 1280).astype(np.float32)
expected_size = X_big_100mb.nbytes / 1e6
print(f"    æ•°ç»„å¤§å°: {expected_size:.1f} MB")
t0 = time.perf_counter()
sc3 = StandardScaler()
out3 = sc3.fit_transform(X_big_100mb)
elapsed = time.perf_counter() - t0
print(f"    è¾“å‡ºå½¢çŠ¶: {out3.shape}")
print(f"    è€—æ—¶: {elapsed*1000:.1f} ms")
print(f"    ç­‰æ•ˆåå: {X_big_100mb.nbytes/elapsed/1e6:.1f} MB/sï¼ˆå« HTTP + GPUï¼‰")
del sc3

# â”€â”€ 4. è¶…å¤§æ•°ç»„ï¼ˆ~500 MBï¼‰â€”â€” æ‰©å±• mmap è½®è½¬ slotâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ³¨æ„ï¼šè¿™æµ‹è¯•äº†æ–°çš„å¤š slot è½®è½¬åˆ†é…æœºåˆ¶
print("\n[4] è¶…å¤§æ•°ç»„ï¼ˆ10000Ã—6400, ~500 MBï¼‰â€”â€” æ‰©å±• mmap è½®è½¬ slot")
X_huge_500mb = np.random.rand(10000, 6400).astype(np.float32)
expected_size = X_huge_500mb.nbytes / 1e6
print(f"    æ•°ç»„å¤§å°: {expected_size:.1f} MB  (è·¨è¶Šå¤šä¸ª 256 MB slot)")

# é¦–å…ˆæµ‹è¯•å®¢æˆ·ç«¯çš„è½®è½¬åˆ†é…
print(f"    ğŸ“  å®¢æˆ·ç«¯ç¼–ç ...")
t0 = time.perf_counter()
from cuml_proxy.proxy import _encode_array
encoded = _encode_array(X_huge_500mb)
encode_time = time.perf_counter() - t0
print(f"       ç¼–ç è€—æ—¶: {encode_time*1000:.1f} ms")

if encoded.get("__mmap__"):
    slot_used = encoded["slot"]
    print(f"       âœ…  ä½¿ç”¨ mmap slot {slot_used}ï¼ˆè‡ªåŠ¨è½®è½¬åˆ†é…ï¼‰")
else:
    print(f"       âŒ  æ„å¤–ï¼šæœªä½¿ç”¨ mmapï¼Œç±»å‹: {list(encoded.keys())}")

# ç°åœ¨æµ‹è¯•å®Œæ•´å¾€è¿”ï¼ˆä½¿ç”¨ PCA å› ä¸ºå®ƒéœ€è¦è¿”å›ç»“æœï¼‰
print(f"    ğŸš€  PCA fit_transform...")
t0 = time.perf_counter()
pca = PCA(n_components=10)
X_pca = pca.fit_transform(X_huge_500mb)
pca_time = time.perf_counter() - t0
print(f"       è€—æ—¶: {pca_time*1000:.1f} ms")
print(f"       è¾“å‡ºå½¢çŠ¶: {X_pca.shape}  (5-dimensional projection)")
print(f"       ç­‰æ•ˆåå: {X_huge_500mb.nbytes/pca_time/1e6:.1f} MB/sï¼ˆå« HTTP + GPUï¼‰")
del pca

# â”€â”€ 5. è¿ç»­å¤šä¸ªå¤§è¯·æ±‚ï¼ˆæµ‹è¯• slot è½®è½¬ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[5] è¿ç»­ 4 ä¸ªå¤§è¯·æ±‚ï¼ˆ~100 MB å„ï¼‰â€”â€” æµ‹è¯• slot è½®è½¬æœºåˆ¶")
print(f"    åˆ›å»º 4 ä¸ªæ¨¡å‹ï¼Œå„å¤„ç† ~100 MB æ•°ç»„...")
times = []
for i in range(4):
    X = np.random.rand(10000, 1280).astype(np.float32)
    t0 = time.perf_counter()
    sc = StandardScaler()
    out = sc.fit_transform(X)
    elapsed = time.perf_counter() - t0
    times.append(elapsed)
    print(f"       [{i+1}] è€—æ—¶: {elapsed*1000:.1f} ms")
    del sc
print(f"    å¹³å‡è€—æ—¶: {np.mean(times)*1000:.1f} ms  (ç¨³å®šæ€§: Â±{np.std(times)*1000:.1f} ms)")

# â”€â”€ 6. éªŒè¯è¾“å‡ºæ­£ç¡®æ€§ï¼ˆå¤§æ•°æ®ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[6] æ­£ç¡®æ€§éªŒè¯ â€”â€” å¤§æ•°ç»„çš„é™ç»´ç»“æœ")
X_large = np.random.randn(5000, 100).astype(np.float32)
pca_verify = PCA(n_components=10)
X_reduced = pca_verify.fit_transform(X_large)
print(f"    è¾“å…¥: {X_large.shape}  â†’  è¾“å‡º: {X_reduced.shape}")
assert X_reduced.shape == (5000, 10), f"å½¢çŠ¶é”™è¯¯: {X_reduced.shape}"
assert np.all(np.isfinite(X_reduced)), "åŒ…å« NaN æˆ– Inf"
print("    âœ…  å½¢çŠ¶å’Œæ•°å€¼æ­£ç¡®")
del pca_verify

# â”€â”€ 7. æ··åˆå¤§å°è¯·æ±‚åºåˆ—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("\n[7] æ··åˆå¤§å°è¯·æ±‚åºåˆ—ï¼ˆæµ‹è¯• base64 + mmap + mmap...ï¼‰")
sizes = [
    (100, 10, "å°"),      # ~4 KB
    (1000, 20, "ä¸­"),     # ~80 KB
    (5000, 640, "å¤§"),    # ~100 MB
]
for rows, cols, label in sizes:
    X = np.random.rand(rows, cols).astype(np.float32)
    size_mb = X.nbytes / 1e6
    t0 = time.perf_counter()
    sc = StandardScaler()
    out = sc.fit_transform(X)
    elapsed = time.perf_counter() - t0
    print(f"    {label:3s} ({size_mb:6.1f} MB): {elapsed*1000:7.1f} ms")
    del sc

print("\n" + "=" * 70)
print(" å…¨éƒ¨æµ‹è¯•é€šè¿‡ âœ…  â€”â€” æ‰©å±• mmap æ¶æ„è¿è¡Œæ­£å¸¸")
print(" â€¢ æ¶ˆé™¤äº† .npy fallback çš„ç£ç›˜ I/O å¼€é”€")
print(" â€¢ æ”¯æŒ 4 GB pool å†…ä»»æ„å¤§å°çš„æ•°æ®")
print(" â€¢ å¤š slot è½®è½¬é¿å…ç«äº‰")
print("=" * 70)
